
# -*- coding: utf-8 -*-
import io
import pandas as pd
import numpy as np
import streamlit as st
import joblib
import pickle as pkl
import base64
from io import BytesIO
from streamlit.components.v1 import html as st_html


from utils import load_model, read_table, feature_names_from_model, cast_inputs, predict_with_model, is_classifier

def show():
    #---------------------------------------------------------------------------------------------
    #ÙƒÙˆØ¯ Ù„Ø­ÙØ¸ Ø§Ù„Ø¬Ù„Ø³Ø©
    # Ù…ÙØ§ØªÙŠØ­ session_state
    MODEL_SESSION_KEY = "sess_model_b64"
    MODEL_NAME_KEY = "sess_model_name"
    DATA_SESSION_KEY = "sess_data_b64"
    DATA_NAME_KEY = "sess_data_name"

    # 2) Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø­ÙØ¸/Ø§Ø³ØªØ±Ø¬Ø§Ø¹ Base64 ÙÙŠ session_state
    def store_file_to_session_state(file_obj, sess_b64_key, sess_name_key):
        """
        ÙŠÙ‚Ø±Ø£ Ø§Ù„Ù…Ù„Ù (UploadedFile Ø£Ùˆ Ù…Ù„Ù-like) ÙˆÙŠØ®Ø²Ù† base64 + name ÙÙŠ st.session_state.
        """
        try:
            file_obj.seek(0)
            raw = file_obj.read()
            b64 = base64.b64encode(raw).decode()
            st.session_state[sess_b64_key] = b64
            st.session_state[sess_name_key] = getattr(file_obj, "name", "uploaded_file")
        except Exception as e:
            st.error(f"ÙØ´Ù„ ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø©: {e}")

    def bytesio_from_session(sess_b64_key, sess_name_key):
        """
        Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ base64 ÙÙŠ session_state ÙŠØ¹ÙŠØ¯ BytesIO Ù…Ø¹ Ø§Ù„Ø®Ø§ØµÙŠØ© name.
        """
        if sess_b64_key in st.session_state:
            try:
                b64 = st.session_state[sess_b64_key]
                raw = base64.b64decode(b64)
                bio = BytesIO(raw)
                bio.name = st.session_state.get(sess_name_key, "restored_file")
                bio.seek(0)
                return bio
            except Exception as e:
                st.warning(f"ÙØ´Ù„ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù…Ù„Ù Ù…Ù† Ø§Ù„Ø¬Ù„Ø³Ø©: {e}")
        return None

    #---------------------------------------------------------------------------------------------
    st.set_page_config(page_title="ØªÙ†Ø¨Ø¤ Ø¯ÙØ¹ÙŠ (Ù…Ù„Ù Excel/CSV)", page_icon="ğŸ“Š", layout="wide")

    st.title("ğŸ“Š ØªÙ†Ø¨Ø¤ Ù„Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ±Ø© Ù…Ù† Ø§Ù„Ø£Ø³Ø± Ø¹Ù„Ù‰ Ù…Ù„Ù Excel/CSV")
    st.caption("Ø§Ø±ÙØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø«Ù… Ø§Ù„Ù…Ù„ÙØ› Ø³Ù†Ø¶ÙŠÙ Ø¹Ù…ÙˆØ¯Ø§Ù‹ Ø¬Ø¯ÙŠØ¯Ø§Ù‹ Ø¨Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª Ù…Ø¹ Ø®ÙŠØ§Ø± ØªÙ†Ø²ÙŠÙ„Ù‡.")

    with st.sidebar:
        st.header("Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
        model_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (.pkl / .joblib)", type=["pkl", "joblib"],  key="uploader_model")
        st.header("Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
        pred_col_name = st.text_input("Ø§Ø³Ù… Ø¹Ù…ÙˆØ¯ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª", value="prediction")
        add_proba = st.checkbox("Ø¥Ø¶Ø§ÙØ© Ø¹Ù…ÙˆØ¯/Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª (Ù„Ù„ØªØµÙ†ÙŠÙ)", value=True)
        st.caption("Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØµÙ†ÙŠÙÙŠØ§Ù‹ ÙˆÙŠØ¯Ø¹Ù… predict_probaØŒ Ø³ÙŠØªÙ… Ø¥Ù„Ø­Ø§Ù‚ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© 'proba_*'.")
    #---------------------------------------------------------------------------------------------
    #ØªØ¨Ø¹ Ø§Ù„Ø¬Ù„Ø³Ø©

    if model_file is not None:
        if (MODEL_NAME_KEY not in st.session_state) or (st.session_state.get(MODEL_NAME_KEY) != getattr(model_file, "name", "")):
            store_file_to_session_state(model_file, MODEL_SESSION_KEY, MODEL_NAME_KEY)
            #st.success("ØªÙ… Ø­ÙØ¸ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø© âœ…")

    result_model_file = None

    if model_file is None:
        restored = bytesio_from_session(MODEL_SESSION_KEY, MODEL_NAME_KEY)
        if restored:
            result_model_file = restored
    else:
    
        result_model_file = model_file


    model_file = result_model_file

    #---------------------------------------------------------------------------------------------
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    model = None
    pipeline = None

    if model_file is not None:
        try:
            # Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… .read() Ù…Ø¹ pickle/joblibØŒ Ù…Ø±Ù‘Ø± ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ù„Ù Ù…Ø¨Ø§Ø´Ø±Ø©
            name = model_file.name.lower()
            model_file.seek(0)  # ØªØ£ÙƒØ¯ Ø£Ù† Ù…Ø¤Ø´Ø± Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
            

            if name.endswith((".joblib",)):
                obj = joblib.load(model_file)
            else:
                obj = pkl.load(model_file)

            # Ù„Ùˆ ÙƒÙ†ØªÙ Ù‚Ø¯ Ø­ÙØ¸ØªÙ Ù‚Ø§Ù…ÙˆØ³Ù‹Ø§ {'pipeline': ...}
            if isinstance(obj, dict) and "pipeline" in obj:
                pipeline = obj["pipeline"]
                model = pipeline
                feature_order = obj["feature_order"]  # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
                metadata = obj.get("metadata", {})
            
            else:
                model = obj
                feature_order = None

            st.success("ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ âœ…")
        except Exception as e:
            st.error(f"ØªØ¹Ø°Ø± ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")



    uploaded = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Excel/CSV)", type=["xlsx", "xls", "csv"], key="uploader_data")

    #---------------------------------------------------------------------------------------------
    #ØªØ¨Ø¹ Ø§Ù„Ø¬Ù„Ø³Ø©
    if uploaded is not None:
        if (DATA_NAME_KEY not in st.session_state) or (st.session_state.get(DATA_NAME_KEY) != getattr(uploaded, "name", "")):
            store_file_to_session_state(uploaded, DATA_SESSION_KEY, DATA_NAME_KEY)
            #st.success("ØªÙ… Ø­ÙØ¸ Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙŠ Ø§Ù„Ø¬Ù„Ø³Ø© âœ…")

    result_uploaded = None

    if uploaded is None:
        restored2 = bytesio_from_session(DATA_SESSION_KEY, DATA_NAME_KEY)
        if restored2:
            result_uploaded = restored2
    else:
        result_uploaded = uploaded

    uploaded = result_uploaded
    #---------------------------------------------------------------------------------------------

    if uploaded is None:
        st.stop()

    try:
        df = read_table(uploaded)
    except Exception as e:
        st.error(f"ØªØ¹Ø°Ø± Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        st.stop()

    st.write("Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:", df.shape)
    st.dataframe(df.head(20))

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø©
    expected = None
    if model is not None:
        expected = feature_names_from_model(model)

        

    st.subheader("ğŸ”§ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤")
    if expected is not None:
        default_cols = [c for c in df.columns if c in expected]
        help_txt = "ØªÙ… Ø§Ù‚ØªØ±Ø§Ø­ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬. ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„Ù‡Ø§."
    else:
        default_cols = list(df.columns)
        help_txt = "Ù„Ù… Ù†Ø³ØªØ·Ø¹ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø£Ø¹Ù…Ø¯Ø© Ù…Ø­Ø¯Ø¯Ø©Ø› Ø§ÙØªØ±Ø§Ø¶ÙŠØ§Ù‹ Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©."

    selected_cols = st.multiselect("Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø¯Ø§Ø®Ù„Ø© Ø¥Ù„Ù‰ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:", options=list(df.columns), default=default_cols, help=help_txt)

    if not selected_cols:
        st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø£Ø¹Ù…Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„.")
        st.stop()

    X = df[selected_cols].copy()

    # Ù†Ø­Ø§ÙˆÙ„ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹: Ø³Ù†ÙØªØ±Ø¶ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø© Ø±Ù‚Ù…ÙŠØ© Ø¥Ù† Ø£Ù…ÙƒÙ†ØŒ ÙˆØ§Ù„Ø¨Ø§Ù‚ÙŠ ÙƒÙ†Øµ
    schema = [{"name": c, "type": "numeric" if pd.api.types.is_numeric_dtype(X[c]) else "text"} for c in selected_cols]
    X_cast = cast_inputs(X, schema)

    if st.button("ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„Ø¹Ù…ÙˆØ¯ âœ…", use_container_width=True):
        if model is None:
            st.error("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø±ÙØ¹ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø£ÙˆÙ„Ø§Ù‹.")
            st.stop()
        try:
            # âœ… ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ©)
            def prepare_input(user_df, feature_order):
                missing_cols = [col for col in feature_order if col not in user_df.columns]
                for col in missing_cols:
                    user_df[col] = np.nan
                # Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
                if missing_cols:
                    st.warning(f"ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù†Ø§Ù‚ØµØ© Ø§Ù„ØªØ§Ù„ÙŠØ© ÙƒÙ€ NaN: {missing_cols}")
                # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ±ØªÙŠØ¨
                return user_df[feature_order]

            # Ø¬Ù‡Ø² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            X_ready = prepare_input(X_cast, feature_order)

            # Ù†ÙØ° Ø§Ù„ØªÙ†Ø¨Ø¤
            out = predict_with_model(model, X_ready)

            y_pred = out["y_pred"]
            out_df = df.copy()
            out_df[pred_col_name] = y_pred

            if add_proba and "y_proba" in out:
                proba = out["y_proba"]
                class_names = out.get("class_names")
                if class_names is None:
                    class_cols = [f"proba_{i}" for i in range(proba.shape[1])]
                else:
                    class_cols = [f"proba_{str(c)}" for c in class_names]
                proba_df = pd.DataFrame(proba, columns=class_cols, index=out_df.index)
                out_df = pd.concat([out_df, proba_df], axis=1)

            st.success("ØªÙ… Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ†Ø¨Ø¤Ø§Øª ÙˆØ¥Ø¶Ø§ÙØªÙ‡Ø§ Ù„Ù„Ø¬Ø¯ÙˆÙ„ âœ…")
            st.dataframe(out_df.head(50))

        except Exception as e:
            st.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")


            # ØªÙ†Ø²ÙŠÙ„ ÙƒÙ…Ù„Ù Excel
            output_buf = io.BytesIO()
            with pd.ExcelWriter(output_buf, engine="openpyxl") as writer:
                out_df.to_excel(writer, index=False, sheet_name="predictions")
            output_buf.seek(0)
            st.download_button(
                label="â¬‡ï¸ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ù…Ù„Ù (Excel)",
                data=output_buf,
                file_name="predictions_with_output.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        except Exception as e:
            st.error(f"Ø­ØµÙ„ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")